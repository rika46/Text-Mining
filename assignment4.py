# -*- coding: utf-8 -*-
"""assignment4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xCjwUl4qyS8-TDe3W8lx4ts9jb_M1nrA
"""

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow import keras
import numpy as np

data = pd.read_csv("crypto_final_final.csv")
data = data[['LABEL','Headline']]
data['Headline']=data['Headline'].values.astype('U')
data = data.reset_index(drop=True)

vectorizer = CountVectorizer(input="content",lowercase=True,max_features=1000)
content_list = data['Headline'].tolist() # Convert dataframe column to a list
vec_matrix = vectorizer.fit_transform(content_list)
vec_array = vec_matrix.toarray()
data_cv = pd.DataFrame(vec_array, columns=vectorizer.get_feature_names_out())
data_cv=data_cv.fillna(0)


X = np.asarray(data_cv).astype(np.float32)

y = np.array(data['LABEL']).T
y = np.array([y]).T

# Perform Label encoding first and then use it for one hot encoding
encoder = LabelEncoder()
# Fit and transform your data
y_encoded = encoder.fit_transform(y)
# Setting some details of our dataframe to variables
InputColumns = X.shape[1]
NumberOfLabels = len(np.unique(y_encoded))
n = len(X)
# Creating one hot labels for y
temp = y_encoded
one_hot_labels = np.zeros((n, NumberOfLabels))
for i in range(n):
    one_hot_labels[i, temp[i]-1] = 1    
y = one_hot_labels
print(y)

# Now the dataframe is ready, split into test/train
X_train, X_test, y_train, y_test = train_test_split(
    X,y,random_state=3333,test_size=0.25, shuffle=True)


# Define the architecture of the Neural Network
model = keras.Sequential([
    keras.layers.Dense(256, input_shape=(1000,), activation='relu'),
    keras.layers.Dense(128, activation = 'relu'),
    keras.layers.Dense(64, activation = 'relu'),
    keras.layers.Dense(4, activation = 'softmax')
])

# Compiling the model
model.compile(optimizer='adam',
              loss=keras.losses.BinaryCrossentropy(),
              metrics=['accuracy'])

# fitting the model
model.fit(X_train, y_train, epochs=100, batch_size=200)

# Evaluating using test and train
results = model.evaluate(X_test, y_test, batch_size=64)

X_train

X_test

print(y_train)
print(y_train.size)

print(y_test)
print(y_test.size)